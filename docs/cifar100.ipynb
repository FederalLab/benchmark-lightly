{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5d2e68",
   "metadata": {},
   "source": [
    "# CIFAR100\n",
    "\n",
    "Loads a federated version of the CIFAR-100 dataset. The dataset is downloaded and cached locally. If previously downloaded, it tries to load the dataset from cache. The dataset is derived from the [CIFAR-100 dataset](https://www.cs.toronto.edu/~kriz/cifar.html). The training and testing examples are partitioned across 500 and 100 clients (respectively). No clients share any data samples, so it is a true partition of CIFAR-100. The train clients have string client IDs in the range [0-499], while the test clients have string client IDs in the range [0-99]. The train clients form a true partition of the CIFAR-100 training split, while the test clients form a true partition of the CIFAR-100 testing split. The data partitioning is done using a hierarchical Latent Dirichlet Allocation\n",
    "(LDA) process, referred to as the [Pachinko Allocation Method](https://people.cs.umass.edu/~mccallum/papers/pam-icml06.pdf) (PAM). This method uses a two-stage LDA process, where each client has an associated multinomial distribution over the coarse labels of CIFAR-100, and a coarse-to-fine label multinomial distribution for that coarse label over the labels under that coarse label. The coarse label multinomial is drawn from a symmetric Dirichlet with parameter 0.1, and each coarse-to-fine multinomial distribution is drawn from a symmetric Dirichlet with parameter 10. Each client has 100 samples. To generate a sample for the client, we first select a coarse label by drawing from the coarse label multinomial distribution, and then draw a fine label using the coarse-to-fine multinomial distribution. We then randomly draw a sample from CIFAR-100 with that label (without replacement). If this exhausts the set of samples with this label, we remove the label from the coarse-to-fine multinomial and re-normalize the multinomial distribution.\n",
    "\n",
    "Data set sizes:\n",
    "\n",
    "- train: 50,000 examples\n",
    "- test: 10,000 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704d391",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89126bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../benchmark/datasets/cifar100 && mkdir -pv data/raw \n",
    "!cd ../benchmark/datasets/cifar100/data/raw && wget --no-check-certificate --no-proxy https://fedml.s3-us-west-1.amazonaws.com/fed_cifar100.tar.bz2\n",
    "!cd ../benchmark/datasets.cifar100/data/raw && tar -xvf fed_cifar100.tar.bz2 && rm fed_cifar100.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302a0f8",
   "metadata": {},
   "source": [
    "### Valid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e449f654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR100(total_parts: 500, total_samples: <bound method CIFAR100.total_samples of <benchmark.datasets.cifar100.cifar100.CIFAR100 object at 0x7fa8d8a266d0>>, current_parts: 0)\n",
      "torch.Size([3, 24, 24]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "from benchmark.datasets.cifar100 import get_cifar100\n",
    "dataset = get_cifar100('../benchmark/datasets/cifar100/data')\n",
    "print(dataset)\n",
    "x, y = dataset[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94229c",
   "metadata": {},
   "source": [
    "## FedAvg, FedSGD, FedEla, FedProx, FedScaffold\n",
    "\n",
    "Run following commands in the root path of `benchmark-lightly`.\n",
    "\n",
    "```bash\n",
    "function cmd(){\n",
    "    fed_optim=$1\n",
    "\n",
    "    task_name=\"cifar100\"\n",
    "    exp_name=${fed_optim}_${task_name}\n",
    "\n",
    "    # Delete cache file\n",
    "    rm -rf /tmp/${exp_name}.share\n",
    "    rm -rf /tmp/${exp_name}\n",
    "    rm -rf ./logs/${task_name}/${fed_optim}\n",
    "\n",
    "    # Run\n",
    "    python -m openfed.tools.launch --nproc_per_node 6  --logdir /tmp benchmark/run.py\\\n",
    "        --fed_init_method file:///tmp/${exp_name}.share\\\n",
    "        --task ${task_name}\\\n",
    "        --data_root benchmark/datasets/${task_name}/data\\\n",
    "        --epochs 1\\\n",
    "        --rounds 4000\\\n",
    "        --act_clts 10\\\n",
    "        --tst_act_clts 10\\\n",
    "        --max_acg_step -1\\\n",
    "        --optim ${fed_optim}\\\n",
    "        --optim_args momentum:0.9 weight_decay:1e-4\\\n",
    "        --follower_lr 0.05\\\n",
    "        --leader_lr 1.0\\\n",
    "        --bz 10\\\n",
    "        --gpu\\\n",
    "        --log_level SUCCESS\\\n",
    "        --log_dir logs\\\n",
    "        --exp_name ${exp_name}\\\n",
    "        --seed 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f9be7",
   "metadata": {},
   "source": [
    "### Run All\n",
    "\n",
    "```bash\n",
    "cmd 'fedavg'; cmd 'fedsgd'; cmd 'fedela'; cmd 'fedprox'; cmd 'fedscaffold'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836db013",
   "metadata": {},
   "source": [
    "## Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from benchmark.utils.plot import plot\n",
    "\n",
    "task_name = \"celeba\"\n",
    "\n",
    "items = dict(\n",
    "    FedAvg=f'../logs/{task_name}/fedavg_{task_name}/{task_name}.json',\n",
    "    FedSgd=f'../logs/{task_name}/fedsgd_{task_name}/{task_name}.json',\n",
    "    FedEla=f'../logs/{task_name}/fedela_{task_name}/{task_name}.json',\n",
    "    FedProx=f'../logs/{task_name}/fedprox_{task_name}/{task_name}.json',\n",
    "    FedScaffold=f'../logs/{task_name}/fedscaffold_{task_name}/{task_name}.json',\n",
    ")\n",
    "\n",
    "files = items.values()\n",
    "labels = items.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bdc12",
   "metadata": {},
   "source": [
    "### Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8635c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc230c",
   "metadata": {},
   "source": [
    "### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2c74f",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a924f",
   "metadata": {},
   "source": [
    "### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf06b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode='test'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
