{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5d2e68",
   "metadata": {},
   "source": [
    "# FEMNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1711af9d",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e863e",
   "metadata": {},
   "source": [
    "### Setup Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec4177",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d32ea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: numpy in /Users/densechen/miniconda3/envs/openfed/lib/python3.7/site-packages (1.20.2)\r\n",
      "Requirement already satisfied: pillow in /Users/densechen/miniconda3/envs/openfed/lib/python3.7/site-packages (8.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851661a6",
   "metadata": {},
   "source": [
    "#### Generate federated dataset\n",
    "\n",
    "Run `bash preprocess.sh` with a choice of the following tags:\n",
    "  - `-s` := 'iid' to sample in an i.i.d. manner, or 'niid' to sample in a non-i.i.d. manner; more information on i.i.d. versus non-i.i.d. is included in the 'Notes' section\n",
    "  - `--iu` := number of users, if iid sampling; expressed as a fraction of the total number of users; default is 0.01\n",
    "  - `--sf` := fraction of data to sample, written as a decimal; default is 0.1\n",
    "  - `-k` := minimum number of samples per user\n",
    "  - `-t` := 'user' to partition users into train-test groups, or 'sample' to partition each user's samples into train-test groups\n",
    "  - `--tf` := fraction of data in training set, written as a decimal; default is 0.9\n",
    "  - `--smplseed` := seed to be used before random sampling of data\n",
    "  - `--spltseed` :=  seed to be used before random split of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb1570f",
   "metadata": {},
   "source": [
    "**Small-sized Dataset** (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3cd8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./preprocess.sh: line 153: realpath: command not found\n",
      "------------------------------\n",
      "sampling data\n",
      "Using seed 1632618444\n",
      "\n",
      "- random seed written out to sampling_seed.txt\n",
      "writing all_data_1_niid_05.json\n",
      "writing all_data_0_niid_05.json\n",
      "writing all_data_6_niid_05.json\n",
      "writing all_data_5_niid_05.json\n",
      "writing all_data_4_niid_05.json\n",
      "writing all_data_3_niid_05.json\n",
      "writing all_data_2_niid_05.json\n",
      "------------------------------\n",
      "removing users with less than 0 samples\n",
      "writing all_data_0_niid_05_keep_0.json\n",
      "writing all_data_1_niid_05_keep_0.json\n",
      "writing all_data_6_niid_05_keep_0.json\n",
      "writing all_data_4_niid_05_keep_0.json\n",
      "writing all_data_3_niid_05_keep_0.json\n",
      "writing all_data_2_niid_05_keep_0.json\n",
      "writing all_data_5_niid_05_keep_0.json\n",
      "------------------------------\n",
      "generating training and test sets\n",
      "- random seed written out to split_seed.txt\n",
      "splitting data by sample\n",
      "writing all_data_0_niid_05_keep_0_train_9.json\n",
      "writing all_data_0_niid_05_keep_0_test_9.json\n",
      "writing all_data_1_niid_05_keep_0_train_9.json\n",
      "writing all_data_1_niid_05_keep_0_test_9.json\n",
      "writing all_data_2_niid_05_keep_0_train_9.json\n",
      "writing all_data_2_niid_05_keep_0_test_9.json\n",
      "writing all_data_3_niid_05_keep_0_train_9.json\n",
      "writing all_data_3_niid_05_keep_0_test_9.json\n",
      "writing all_data_5_niid_05_keep_0_train_9.json\n",
      "writing all_data_5_niid_05_keep_0_test_9.json\n",
      "writing all_data_4_niid_05_keep_0_train_9.json\n",
      "writing all_data_4_niid_05_keep_0_test_9.json\n",
      "writing all_data_6_niid_05_keep_0_train_9.json\n",
      "writing all_data_6_niid_05_keep_0_test_9.json\n",
      "------------------------------\n",
      "calculating JSON file checksums\n",
      "find: fts_read: Invalid argument\n",
      "checksums written to meta/dir-checksum.md5\n"
     ]
    }
   ],
   "source": [
    "# Clear tmp folder\n",
    "!cd ../benchmark/datasets/femnist/ && rm -rf data/rem_user_data data/sampled_data data/test data/train\n",
    "\n",
    "# Download data and sampling\n",
    "!cd ../benchmark/datasets/femnist/ && bash preprocess.sh -s niid --sf 0.05 -k 0 -t sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83a892",
   "metadata": {},
   "source": [
    "**Full-sized Dataset** (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear tmp folder\n",
    "!cd ../benchmark/datasets/femnist/ && rm -rf data/rem_user_data data/sampled_data data/test data/train\n",
    "\n",
    "# Download data and sampling\n",
    "!cd ../benchmark/datasets/femnist/ && bash preprocess.sh -s niid --sf 1.0 -k 0 -t sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8ab95",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- More details on i.i.d. versus non-i.i.d.:\n",
    "  - In the i.i.d. sampling scenario, each data-point is equally likely to be sampled. Thus, all users have the same underlying distribution of data.\n",
    "  - In the non-i.i.d. sampling scenario, the underlying distribution of data for each user is consistent with the raw data. Since we assume that data distributions vary between user in the raw data, we refer to this sampling process as non-i.i.d.\n",
    "- More details on `preprocess.sh`:\n",
    "  - The order in which `preprocess.sh` processes data is 1. generating all_data, 2. sampling, 3. removing users, and 4. creating train-test split. The script will look at the data in the last generated directory and continue preprocessing from that point. For example, if the `all_data` directory has already been generated and the user decides to skip sampling and only remove users with the `-k` tag (i.e. running `preprocess.sh -k 50`), the script will effectively apply a remove user filter to data in `all_data` and place the resulting data in the `rem_user_data` directory.\n",
    "  - File names provide information about the preprocessing steps taken to generate them. For example, the `all_data_niid_1_keep_64.json` file was generated by first sampling 10 percent (.1) of the data `all_data.json` in a non-i.i.d. manner and then applying the `-k 64` argument to the resulting data.\n",
    "- Each .json file is an object with 3 keys:\n",
    "  1. 'users', a list of users\n",
    "  2. 'num_samples', a list of the number of samples for each user, and\n",
    "  3. 'user_data', an object with user names as keys and their respective data as values; for each user, data is represented as a list of images, with each image represented as a size-784 integer list (flattened from 28 by 28)\n",
    "- Run `./stats.sh` to get statistics of data (data/all_data/all_data.json must have been generated already)\n",
    "- In order to run reference implementations in `../models` directory, the `-t sample` tag must be used when running `./preprocess.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfea69a",
   "metadata": {},
   "source": [
    "### Valid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b6acea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimulationDataset(total_parts: 36, total_samples: 8964, current_parts: 0)\n",
      "torch.Size([784]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "from benchmark.datasets.femnist import get_femnist\n",
    "dataset = get_femnist('../benchmark/datasets/femnist/data')\n",
    "print(dataset)\n",
    "x, y = dataset[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94229c",
   "metadata": {},
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2e0d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Stdout and stderr for collaborator-1 will be written to /tmp/openfed_node_collaborator-1_stdout, /tmp/openfed_node_collaborator-1_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-2 will be written to /tmp/openfed_node_collaborator-2_stdout, /tmp/openfed_node_collaborator-2_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-3 will be written to /tmp/openfed_node_collaborator-3_stdout, /tmp/openfed_node_collaborator-3_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-4 will be written to /tmp/openfed_node_collaborator-4_stdout, /tmp/openfed_node_collaborator-4_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-5 will be written to /tmp/openfed_node_collaborator-5_stdout, /tmp/openfed_node_collaborator-5_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-6 will be written to /tmp/openfed_node_collaborator-6_stdout, /tmp/openfed_node_collaborator-6_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-7 will be written to /tmp/openfed_node_collaborator-7_stdout, /tmp/openfed_node_collaborator-7_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-8 will be written to /tmp/openfed_node_collaborator-8_stdout, /tmp/openfed_node_collaborator-8_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-9 will be written to /tmp/openfed_node_collaborator-9_stdout, /tmp/openfed_node_collaborator-9_stderr respectively.\n",
      "Note: Stdout and stderr for collaborator-10 will be written to /tmp/openfed_node_collaborator-10_stdout, /tmp/openfed_node_collaborator-10_stderr respectively.\n",
      ">>> Load Props\n",
      "<OpenFed> FederatedProperties\n",
      "+--------------------+------------+\n",
      "|        role        | nick_name  |\n",
      "+--------------------+------------+\n",
      "| openfed_aggregator | aggregator |\n",
      "+--------------------+------------+\n",
      "<OpenFed> Address\n",
      "+---------+---------------------+------------+------+\n",
      "| backend |     init_method     | world_size | rank |\n",
      "+---------+---------------------+------------+------+\n",
      "|   gloo  | file:///...aredfile |     11     |  0   |\n",
      "+---------+---------------------+------------+------+\n",
      "\n",
      "\n",
      ">>> Seed everything...\n",
      ">>> Log argparse to json...\n",
      ">>> Config device...\n",
      "{'task': 'femnist', 'network_args': {}, 'data_root': '../benchmark/datasets/femnist/data', 'partition': 'iid', 'partition_args': {}, 'num_parts': 100, 'tst_num_parts': 10, 'dataset_args': {}, 'epochs': 1, 'rounds': 20, 'act_clts': 10, 'act_clts_rat': 1.0, 'tst_act_clts': 10, 'tst_act_clts_rat': 1.0, 'max_acg_step': -1, 'optim': 'fedavg', 'optim_args': {'momentum': 0.9, 'weight_decay': 0.0001}, 'co_lr': 0.1, 'ag_lr': 1.0, 'bz': 10, 'gpu': True, 'log_dir': 'logs/femnist/fedavg_', 'seed': 0, 'props': '/tmp/aggregator.json', 'exp_name': 'fedavg_', 'device': device(type='cpu')}\n",
      "\tLet's use cpu.\n",
      ">>> Load dataset...\n",
      "SimulationDataset(total_parts: 36, total_samples: 8964, current_parts: 0)\n",
      "SimulationDataset(total_parts: 36, total_samples: 1013, current_parts: 0)\n",
      ">>> Load dataLoader...\n",
      ">>> Build network...\n",
      "Femnist(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (logits): Linear(in_features=512, out_features=62, bias=True)\n",
      "  (loss_fn): CrossEntropyLoss()\n",
      ")\n",
      ">>> Move to device...\n",
      ">>> Federated Optimizer...\n",
      ">>> Lr Scheduler...\n",
      ">>> Maintainer...\n",
      "[W ProcessGroupGloo.cpp:559] Warning: Unable to resolve hostname to a (local) address. Using the loopback address as fallback. Manually set the network interface to bind to with GLOO_SOCKET_IFNAME. (function operator())\n",
      ">>> Register hooks...\n",
      "\tTrain Part: 36\n",
      "\tActivated Train Part: 10\n",
      "\tTest Part: 36\n",
      "\tActivated Test Part: 10\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]/Users/densechen/code/OpenFed/openfed/functional/agg.py:31: UserWarning: Load param state for 0 params, 8 params are ignored.\n",
      "  warnings.warn(f'Load param state for {success} params, '\n",
      "  0%|                                                    | 0/20 [00:01<?, ?it/s]\n",
      "Exception in thread Thread-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/densechen/miniconda3/envs/openfed/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/densechen/code/OpenFed/openfed/api.py\", line 85, in run\n",
      "    **reduce_func_kwargs)\n",
      "  File \"/Users/densechen/code/benchmark-lightly/benchmark/utils/reduce.py\", line 11, in meta_reduce_log\n",
      "    reduce_meta['mode'] = meta_list[0]['mode']\n",
      "IndexError: list index out of range\n",
      "\n",
      "Killing subprocess 50764\n",
      "Killing subprocess 50765\n",
      "Killing subprocess 50766\n",
      "Killing subprocess 50767\n",
      "Killing subprocess 50768\n",
      "Killing subprocess 50769\n",
      "Killing subprocess 50770\n",
      "Killing subprocess 50771\n",
      "Killing subprocess 50772\n",
      "Killing subprocess 50773\n",
      "Killing subprocess 50774\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/densechen/miniconda3/envs/openfed/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/densechen/miniconda3/envs/openfed/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/densechen/code/OpenFed/openfed/tools/simulator.py\", line 214, in <module>\n",
      "    main()\n",
      "  File \"/Users/densechen/code/OpenFed/openfed/tools/simulator.py\", line 197, in main\n",
      "    sigkill_handler(signal.SIGTERM, None)\n",
      "  File \"/Users/densechen/code/OpenFed/openfed/tools/simulator.py\", line 131, in sigkill_handler\n",
      "    returncode=last_return_code, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/Users/densechen/miniconda3/envs/openfed/bin/python', '-u', '../main.py', '--task', 'femnist', '--data_root', '../benchmark/datasets/femnist/data', '--epochs', '1', '--rounds', '20', '--act_clts', '10', '--tst_act_clts', '10', '--max_acg_step', '-1', '--optim', 'fedavg', '--optim_args', 'momentum:0.9', 'weight_decay:1e-4', '--co_lr', '1e-1', '--ag_lr', '1.0', '--bz', '10', '--gpu', '--log_dir', 'logs', '--seed', '0', '--props=/tmp/collaborator-10.json']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!python -m openfed.tools.simulator --nproc 11  --logdir /tmp ../main.py\\\n",
    "    --task femnist\\\n",
    "    --data_root ../benchmark/datasets/femnist/data\\\n",
    "    --epochs 1\\\n",
    "    --rounds 20\\\n",
    "    --act_clts 10\\\n",
    "    --tst_act_clts 10\\\n",
    "    --max_acg_step -1\\\n",
    "    --optim fedavg\\\n",
    "    --optim_args momentum:0.9 weight_decay:1e-4\\\n",
    "    --co_lr 1e-1\\\n",
    "    --ag_lr 1.0\\\n",
    "    --bz 10\\\n",
    "    --gpu\\\n",
    "    --log_dir logs\\\n",
    "    --seed 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d79ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
