{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5d2e68",
   "metadata": {},
   "source": [
    "# Sent140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e28957",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fd563",
   "metadata": {},
   "source": [
    "### Setup Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355e71",
   "metadata": {},
   "source": [
    "#### Generate embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../benchmark/datasets/sent140 && bash get_embs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487b75e",
   "metadata": {},
   "source": [
    "#### Generate federated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891a0f1e",
   "metadata": {},
   "source": [
    "Run `bash preprocess.sh` with a choice of the following tags:\n",
    "- `-s` := 'iid' to sample in an i.i.d. manner, or 'niid' to sample in a non-i.i.d. manner; more information on i.i.d. versus non-i.i.d. is included in the 'Notes' section\n",
    "- `--iu` := number of users, if iid sampling; expressed as a fraction of the total number of users; default is 0.01\n",
    "- `--sf` := fraction of data to sample, written as a decimal; default is 0.1\n",
    "- `-k` := minimum number of samples per user\n",
    "- `-t` := 'user' to partition users into train-test groups, or 'sample' to partition each user's samples into train-test groups\n",
    "- `--tf` := fraction of data in training set, written as a decimal; default is 0.9\n",
    "- `--smplseed` := seed to be used before random sampling of data\n",
    "- `--spltseed` :=  seed to be used before random split of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c5008",
   "metadata": {},
   "source": [
    "**Small-sized Dataset** (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a5bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear tmp folder\n",
    "!cd ../benchmark/datasets/sent140/ && rm -rf data/rem_user_data data/sampled_data data/test data/train\n",
    "\n",
    "# Download data and sampling\n",
    "!cd ../benchmark/datasets/sent140/ && bash preprocess.sh -s niid --sf 0.05 -k 0 -t sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad881118",
   "metadata": {},
   "source": [
    "**Full-sized Dataset** (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear tmp folder\n",
    "!cd ../benchmark/datasets/sent140/ && rm -rf data/rem_user_data data/sampled_data data/test data/train\n",
    "\n",
    "# Download data and sampling\n",
    "!cd ../benchmark/datasets/sent140/ && bash preprocess.sh -s niid --sf 1.0 -k 0 -t sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c7091",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- More details on i.i.d. versus non-i.i.d.:\n",
    "  - In the i.i.d. sampling scenario, each data-point is equally likely to be sampled. Thus, all users have the same underlying distribution of data.\n",
    "  - In the non-i.i.d. sampling scenario, the underlying distribution of data for each user is consistent with the raw data. Since we assume that data distributions vary between user in the raw data, we refer to this sampling process as non-i.i.d.\n",
    "- More details on `preprocess.sh`:\n",
    "  - The order in which `preprocess.sh` processes data is 1. generating all_data, 2. sampling, 3. removing users, and 4. creating train-test split. The script will look at the data in the last generated directory and continue preprocessing from that point. For example, if the `all_data` directory has already been generated and the user decides to skip sampling and only remove users with the `-k` tag (i.e. running `preprocess.sh -k 50`), the script will effectively apply a remove user filter to data in `all_data` and place the resulting data in the `rem_user_data` directory.\n",
    "  - File names provide information about the preprocessing steps taken to generate them. For example, the `all_data_niid_1_keep_64.json` file was generated by first sampling 10 percent (.1) of the data `all_data.json` in a non-i.i.d. manner and then applying the `-k 64` argument to the resulting data.\n",
    "- The training data has been preprocessed so that the emoji characters have been removed\n",
    "- Each .json file is an object with 3 keys:\n",
    "  1. 'users', a list of users\n",
    "  2. 'num_samples', a list of the number of samples for each user, and\n",
    "  3. 'user_data', an object with user names as keys and their respective data as values; for each user, data is represented as a list of attribute lists, with each attribute list containing the following string-valued features at the corresponding indices:\n",
    "     - `0`: id of the tweet; i.e '2087'\n",
    "     - `1`: date of the tweet; i.e. 'Sat May 16 23:58:44 UTC 2009'\n",
    "     - `2`: query; i.e. 'lyx'; if there is no query, then this value is 'NO_QUERY'\n",
    "     - `3`: user that tweeted; i.e. 'robotickilldozr'\n",
    "     - `4`: text of the tweet; i.e. 'Lyx is cool'\n",
    "    (examples based on [Sentiment140 website](http://help.sentiment140.com/for-students/))\n",
    "- Run `./stats.sh` to get statistics of data (data/all_data/all_data.json must have been generated already)\n",
    "- In order to run reference implementations, the `-t sample` tag must be used when running `./preprocess.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ee89a",
   "metadata": {},
   "source": [
    "### Valid dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d2f4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent140(total_parts: 254555, total_samples: 908652, current_parts: 0)\n",
      "torch.Size([400000]) torch.Size([2])\n",
      "vocab size: 400000\n"
     ]
    }
   ],
   "source": [
    "from benchmark.datasets.sent140 import get_sent140\n",
    "dataset = get_sent140('../benchmark/datasets/sent140/data')\n",
    "print(dataset)\n",
    "x, y = dataset[0]\n",
    "print(x.shape, y.shape)\n",
    "print(f'vocab size: {dataset.vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94229c",
   "metadata": {},
   "source": [
    "## FedAvg, FedSGD, FedEla, FedProx, FedScaffold\n",
    "\n",
    "Run following commands in the root path of `benchmark-lightly`.\n",
    "\n",
    "\n",
    "```bash\n",
    "function cmd(){\n",
    "    fed_optim=$1\n",
    "    sub_task_name=$2\n",
    "\n",
    "    task_name=\"sent140\"\n",
    "    \n",
    "    exp_name=${fed_optim}_${task_name}_${sub_task_name}\n",
    "\n",
    "    # Delete cache file\n",
    "    rm -rf /tmp/${exp_name}.share\n",
    "    rm -rf /tmp/${exp_name}\n",
    "    rm -rf ./logs/${task_name}/${fed_optim}\n",
    "\n",
    "    # Run\n",
    "    python -m openfed.tools.launch --nproc_per_node 6  --logdir /tmp benchmark/run.py\\\n",
    "        --fed_init_method file:///tmp/${exp_name}.share\\\n",
    "        --task ${task_name}\\\n",
    "        --network_args task:\"r\\\"${sub_task_name}\\\"\"\\\n",
    "        --data_root benchmark/datasets/${task_name}/data\\\n",
    "        --dataset_args task:\"r\\\"${sub_task_name}\\\"\"\\\n",
    "        --epochs 1\\\n",
    "        --rounds 20\\\n",
    "        --act_clts 100\\\n",
    "        --tst_act_clts 100\\\n",
    "        --max_acg_step -1\\\n",
    "        --optim ${fed_optim}\\\n",
    "        --optim_args momentum:0.9 weight_decay:1e-4\\\n",
    "        --follower_lr 1e-1\\\n",
    "        --leader_lr 1.0\\\n",
    "        --bz 10\\\n",
    "        --gpu\\\n",
    "        --log_level SUCCESS\\\n",
    "        --log_dir logs\\\n",
    "        --exp_name ${exp_name}\\\n",
    "        --seed 0\n",
    "}\n",
    "\n",
    "function cmd_bag_log_reg(){\n",
    "    cmd $1 'bag_log_reg'\n",
    "}\n",
    "\n",
    "function cmd_stacked_lstm(){\n",
    "    cmd $1 'stacked_lstm'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741ceac5",
   "metadata": {},
   "source": [
    "##  bag_log_reg\n",
    "\n",
    "```bash\n",
    "cmd_bag_log_reg 'fedavg'; cmd_bag_log_reg 'fedsgd'; cmd_bag_log_reg 'fedela'; cmd_bag_log_reg 'fedprox'; cmd_bag_log_reg 'fedscaffold'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836db013",
   "metadata": {},
   "source": [
    "## Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from benchmark.utils.plot import plot\n",
    "\n",
    "task_name = \"sent140\"\n",
    "sub_task_name = \"bag_log_reg\"\n",
    "\n",
    "items = dict(\n",
    "    FedAvg=f'../logs/{task_name}/fedavg_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedSgd=f'../logs/{task_name}/fedsgd_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedEla=f'../logs/{task_name}/fedela_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedProx=f'../logs/{task_name}/fedprox_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedScaffold=f'../logs/{task_name}/fedscaffold_{task_name}_{sub_task_name}/{task_name}.json',\n",
    ")\n",
    "\n",
    "files = items.values()\n",
    "labels = items.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bdc12",
   "metadata": {},
   "source": [
    "### Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8635c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc230c",
   "metadata": {},
   "source": [
    "### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2c74f",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a924f",
   "metadata": {},
   "source": [
    "### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf06b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode='test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec252c",
   "metadata": {},
   "source": [
    "## stacked_lstm\n",
    "\n",
    "```bash\n",
    "cmd_stacked_lstm 'fedavg'; cmd_stacked_lstm 'fedsgd'; cmd_stacked_lstm 'fedela'; cmd_stacked_lstm 'fedprox'; cmd_stacked_lstm 'fedscaffold'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53cf07",
   "metadata": {},
   "source": [
    "## Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from benchmark.utils.plot import plot\n",
    "\n",
    "task_name = \"sent140\"\n",
    "sub_task_name = \"bag_log_reg\"\n",
    "\n",
    "items = dict(\n",
    "    FedAvg=f'../logs/{task_name}/fedavg_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedSgd=f'../logs/{task_name}/fedsgd_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedEla=f'../logs/{task_name}/fedela_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedProx=f'../logs/{task_name}/fedprox_{task_name}_{sub_task_name}/{task_name}.json',\n",
    "    FedScaffold=f'../logs/{task_name}/fedscaffold_{task_name}_{sub_task_name}/{task_name}.json',\n",
    ")\n",
    "\n",
    "files = items.values()\n",
    "labels = items.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45778fc8",
   "metadata": {},
   "source": [
    "### Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bc9c87",
   "metadata": {},
   "source": [
    "### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73d1137",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ed17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399d6a90",
   "metadata": {},
   "source": [
    "### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2994a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode='test'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
