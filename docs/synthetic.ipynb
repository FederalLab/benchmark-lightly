{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5d2e68",
   "metadata": {},
   "source": [
    "# Synthetic\n",
    "\n",
    "\n",
    "We propose a process to generate synthetic federated datasets. The dataset is inspired by the one presented by [Li et al.](https://arxiv.org/abs/1905.10497), but has possible additional heterogeneity designed to make current meta-learning methods (such as [Reptile](https://openai.com/blog/reptile/)) struggle. The high-level goal is to create tasks whose true models are (1) task-dependant, and (2) clustered around more than just one center. To see a description of the whole generative process, please refer to the LEAF paper.\n",
    "\n",
    "We note that, at the moment, we default to one cluster of models in our code. This can be easily changed by modifying the PROB_CLUSTERS constant in ```main.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a12f64",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b67d25",
   "metadata": {},
   "source": [
    "### Setup instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd29d0f",
   "metadata": {},
   "source": [
    "#### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fe75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2399cf",
   "metadata": {},
   "source": [
    "#### Generate initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1523ed7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset\n",
      "Done :D\n"
     ]
    }
   ],
   "source": [
    "!cd ../benchmark/datasets/synthetic && python main.py -num-tasks 1000 -num-classes 5 -num-dim 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64da2a",
   "metadata": {},
   "source": [
    "#### Generate federated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fdfe1e",
   "metadata": {},
   "source": [
    "Run `bash ./preprocess.sh` (as with the other LEAF datasets) to produce the final data splits. We suggest using the following tags:\n",
    "- `--sf` := fraction of data to sample, written as a decimal; set it to 1.0 in order to keep the number of tasks/users specified earlier.\n",
    "- `-k` := minimum number of samples per user; set it to 5.\n",
    "- `-t` := 'user' to partition users into train-test groups, or 'sample' to partition each user's samples into train-test groups.\n",
    "- `--tf` := fraction of data in training set, written as a decimal; default is 0.9.\n",
    "- `--smplseed` := seed to be used before random sampling of data.\n",
    "- `--spltseed` :=  seed to be used before random split of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92505329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./preprocess.sh: line 153: realpath: command not found\n",
      "------------------------------\n",
      "sampling data\n",
      "Using seed 1632624149\n",
      "\n",
      "- random seed written out to sampling_seed.txt\n",
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n",
      "writing data_niid_0.json\n",
      "------------------------------\n",
      "removing users with less than 5 samples\n",
      "writing data_niid_0_keep_5.json\n",
      "------------------------------\n",
      "generating training and test sets\n",
      "- random seed written out to split_seed.txt\n",
      "splitting data by sample\n",
      "writing data_niid_0_keep_5_train_6.json\n",
      "writing data_niid_0_keep_5_test_6.json\n",
      "------------------------------\n",
      "calculating JSON file checksums\n",
      "checksums written to meta/dir-checksum.md5\n"
     ]
    }
   ],
   "source": [
    "!cd ../benchmark/datasets/synthetic && rm -rf data/rem_user_data data/sampled_data data/test data/train\n",
    "!cd ../benchmark/datasets/synthetic && bash preprocess.sh -s niid --sf 1.0 -k 5 -t sample --tf 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09a4b1",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- More details on `preprocess.sh`:\n",
    "  - The order in which `preprocess.sh` processes data is 1. generating all_data (done here by the `main.py` script), 2. sampling, 3. removing users, and 4. creating train-test split. The script will look at the data in the last generated directory and continue preprocessing from that point. For example, if the `all_data` directory has already been generated and the user decides to skip sampling and only remove users with the `-k` tag (i.e. running `preprocess.sh -k 50`), the script will effectively apply a remove user filter to data in `all_data` and place the resulting data in the `rem_user_data` directory.\n",
    "  - File names provide information about the preprocessing steps taken to generate them. For example, the `all_data_niid_1_keep_64.json` file was generated by first sampling 10 percent (.1) of the data `all_data.json` in a non-i.i.d. manner and then applying the `-k 64` argument to the resulting data.\n",
    "- Each .json file is an object with 3 keys:\n",
    "  1. 'users', a list of users\n",
    "  2. 'num_samples', a list of the number of samples for each user, and\n",
    "  3. 'user_data', an object with user names as keys and their respective data as values.\n",
    "- Run `./stats.sh` to get statistics of data (data/all_data/all_data.json must have been generated already)\n",
    "- In order to run reference implementations, the `-t sample` tag must be used when running `./preprocess.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736d1ba",
   "metadata": {},
   "source": [
    "### Valid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3df9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimulationDataset(total_parts: 1000, total_samples: 64153, current_parts: 0)\n",
      "torch.Size([60]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "from benchmark.datasets.synthetic import get_synthetic\n",
    "dataset = get_synthetic('../benchmark/datasets/synthetic/data')\n",
    "print(dataset)\n",
    "x, y = dataset[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94229c",
   "metadata": {},
   "source": [
    "## FedAvg, FedSGD, FedEla, FedProx, FedScaffold\n",
    "\n",
    "Run following commands in the root path of `benchmark-lightly`.\n",
    "\n",
    "```bash\n",
    "function cmd(){\n",
    "    fed_optim=$1\n",
    "\n",
    "    task_name=\"synthetic\"\n",
    "    exp_name=${fed_optim}_${task_name}\n",
    "\n",
    "    # Delete cache file\n",
    "    rm -rf /tmp/${exp_name}.share\n",
    "    rm -rf /tmp/${exp_name}\n",
    "    rm -rf ./logs/${task_name}/${fed_optim}\n",
    "\n",
    "    # Run\n",
    "    python -m openfed.tools.launch --nproc_per_node 6  --logdir /tmp benchmark/run.py\\\n",
    "        --fed_init_method file:///tmp/${exp_name}.share\\\n",
    "        --task ${task_name}\\\n",
    "        --data_root benchmark/datasets/${task_name}/data\\\n",
    "        --epochs 1\\\n",
    "        --rounds 20\\\n",
    "        --act_clts 100\\\n",
    "        --tst_act_clts 100\\\n",
    "        --max_acg_step -1\\\n",
    "        --optim ${fed_optim}\\\n",
    "        --optim_args momentum:0.9 weight_decay:1e-4\\\n",
    "        --follower_lr 1e-1\\\n",
    "        --leader_lr 1.0\\\n",
    "        --bz 10\\\n",
    "        --gpu\\\n",
    "        --log_level SUCCESS\\\n",
    "        --log_dir logs\\\n",
    "        --exp_name ${exp_name}\\\n",
    "        --seed 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5f9be7",
   "metadata": {},
   "source": [
    "### Run All\n",
    "\n",
    "```bash\n",
    "cmd 'fedavg'; cmd 'fedsgd'; cmd 'fedela'; cmd 'fedprox'; cmd 'fedscaffold'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836db013",
   "metadata": {},
   "source": [
    "## Plot Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from benchmark.utils.plot import plot\n",
    "\n",
    "task_name = \"synthetic\"\n",
    "\n",
    "items = dict(\n",
    "    FedAvg=f'../logs/{task_name}/fedavg_{task_name}/{task_name}.json',\n",
    "    FedSgd=f'../logs/{task_name}/fedsgd_{task_name}/{task_name}.json',\n",
    "    FedEla=f'../logs/{task_name}/fedela_{task_name}/{task_name}.json',\n",
    "    FedProx=f'../logs/{task_name}/fedprox_{task_name}/{task_name}.json',\n",
    "    FedScaffold=f'../logs/{task_name}/fedscaffold_{task_name}/{task_name}.json',\n",
    ")\n",
    "\n",
    "files = items.values()\n",
    "labels = items.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bdc12",
   "metadata": {},
   "source": [
    "### Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8635c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc230c",
   "metadata": {},
   "source": [
    "### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f233dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc2c74f",
   "metadata": {},
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5472fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"accuracy\",\n",
    "    mode=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a924f",
   "metadata": {},
   "source": [
    "### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf06b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    files=files,\n",
    "    labels=labels,\n",
    "    attributes=\"loss\",\n",
    "    mode='test'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
